{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the csv file\n",
    "imdb=pd.read_csv('IMDB Dataset.csv')\n",
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length of text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>50000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1309.67016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>990.02418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>32.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>699.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>971.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1591.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>13704.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       length of text\n",
       "count     50000.00000\n",
       "mean       1309.67016\n",
       "std         990.02418\n",
       "min          32.00000\n",
       "25%         699.00000\n",
       "50%         971.00000\n",
       "75%        1591.00000\n",
       "max       13704.00000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Considering only the length of text >2000\n",
    "newimdb=imdb[imdb['length of text']>2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review            8415\n",
       "length of text    8415\n",
       "sentiment         8415\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newimdb.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive=newimdb[newimdb['sentiment']=='positive']\n",
    "negative=newimdb[newimdb['sentiment']=='negative']\n",
    "plt.hist(newimdb['sentiment']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing punctuation and forming \"bag of words\" with each word and \n",
    "##their corresponding occurences in the dataset\n",
    "from string import punctuation\n",
    "words_bag={}\n",
    "punctuation_list=list(punctuation)\n",
    "maxWordsInReview=0\n",
    "for review in newimdb['review']:\n",
    "    review_lower_split=review.lower().split()\n",
    "    if len(review_lower_split)> maxWordsInReview:\n",
    "        maxWordsInReview= len(review_lower_split)\n",
    "    wordlist=[word for word in review_lower_split  if word.isalpha() ]\n",
    "    for i in wordlist:\n",
    "        words_bag[i]=words_bag.get(i,0)+1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Top 25K sorted words according to their frequent occurences\n",
    "\n",
    "top25k_sorted_wordcount=sorted(words_bag.values(),reverse=True)[:25000]\n",
    "final_word_bag=[k for k in words_bag.keys()   if words_bag[k] in top25k_sorted_wordcount]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Forming bag of words with the top 25K words\n",
    "final_word_bag_dict={}\n",
    "for i in range(1,len(final_word_bag)+1):\n",
    "    final_word_bag_dict[final_word_bag[i-1]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8415, 2470)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating an empty matrix X\n",
    "X=np.zeros(newimdb['review'].count()*(maxWordsInReview)).reshape(newimdb['review'].count(),maxWordsInReview)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating matrix X according to the words in each of the  review in the dataset\n",
    "i=0\n",
    "for A in newimdb['review']:\n",
    "    for j,review in enumerate(A.split()):\n",
    "        review_lower_split=review.lower()\n",
    "        pos=final_word_bag_dict.get(review_lower_split,0)\n",
    "        X[i,j]=int(pos)\n",
    "    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5385 1683 1347\n"
     ]
    }
   ],
   "source": [
    "#split_dataset into 70% training , 20% test and 10% Validation Dataset\n",
    "y=[1 if j=='positive' else 0 for j in newimdb['sentiment']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=10)\n",
    "print(len(X_train),  len(X_test),len(X_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converting the numpy array into tensor\n",
    "x_train, x_valid,x_test  = map( torch.LongTensor, (X_train, X_valid,X_test))\n",
    "y_train,  y_valid,y_test = map( torch.FloatTensor, ( y_train,y_valid,y_test))\n",
    "# train_data, valid_data, test_y,valid_y = train_test_split(X_train, y_train, test_size=0.10, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining the model\n",
    "class Linearmodel(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embed_dim, output_dim, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocabulary_size, embed_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.fc = nn.Linear(embed_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        # Takes 64 reviews, each column represents a single review\n",
    "        # Each word in the review is transformed to 100 dimention by using glove\n",
    "        # So, input [x,64] -> [x,64,100]\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        # Changes dimension ie input with 3 dim,0 becomes 1st dim, 1 becomes 0 dim, 2 remains same  [x,64,100]->[64,x,100]\n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #average x into 1 ie [x,64,100] -> [64,100]\n",
    "        pooled = F.avg_pool2d(embedded, (embedded.shape[1], 1)).squeeze(1) \n",
    "\n",
    "        # transform y=Ax+b ie  y=1 0r 0, x=[64*100] , A is weight matrix adjusted b is bias        \n",
    "        return self.fc(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the model\n",
    "model = Linearmodel(len(final_word_bag)+1, 100, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing the Weights and the bias\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculating accuracy of the model\n",
    "def accuracy(pred, y):\n",
    "\n",
    "    pred_round = torch.round(torch.sigmoid(pred))\n",
    "    correct = (pred_round == y).float()  \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Spliting into batches\n",
    "batchSize=64\n",
    "trainBatches=x_train.split(64)\n",
    "trainYBatches=y_train.split(64)\n",
    "validXBatches=x_valid.split(64)\n",
    "validYBatches=y_valid.split(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining the train process\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for i,batch in enumerate(trainBatches):\n",
    "        permutedBatch=batch.permute(1,0)\n",
    "        optimizer.zero_grad()\n",
    "        pred= model(permutedBatch).squeeze(1)\n",
    "        #print(pred)\n",
    "        #print(torch.FloatTensor(trainYBatches[i]))\n",
    "        loss = criterion(pred, trainYBatches[i])\n",
    "        acc = accuracy(pred,trainYBatches[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_acc += acc.item()\n",
    "    return (total_loss / len(trainBatches), total_acc / len(trainBatches))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining Evaluation process\n",
    "def evaluate():\n",
    "    total_loss = 0\n",
    "    total_acc = 0    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,batch in enumerate(validXBatches):\n",
    "            permutedBatch=batch.permute(1,0)\n",
    "            pred = model(permutedBatch).squeeze(1)\n",
    "            loss = criterion(pred, validYBatches[i])\n",
    "            acc = accuracy(pred,validYBatches[i])\n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc.item()\n",
    "    return total_loss / len(validXBatches), total_acc / len(validXBatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Accuracy 0 (0.6921116555438322, 0.5149918303770178)\n",
      "EVAL Accuracy 0 (0.6902858885851774, 0.5203598493879492)\n",
      "TRAIN Accuracy 1 (0.6874231717165779, 0.5238153597887825)\n",
      "EVAL Accuracy 1 (0.6860704313624989, 0.5203598493879492)\n",
      "TRAIN Accuracy 2 (0.6809495624373941, 0.5280637257239398)\n",
      "EVAL Accuracy 2 (0.6789116398854689, 0.53314394029704)\n",
      "TRAIN Accuracy 3 (0.669961404800415, 0.5666870916590971)\n",
      "EVAL Accuracy 3 (0.6669615371660753, 0.6178977272727273)\n",
      "TRAIN Accuracy 4 (0.6527825769256143, 0.6663398693589603)\n",
      "EVAL Accuracy 4 (0.6495022855021737, 0.6896306818181818)\n",
      "TRAIN Accuracy 5 (0.6293726549429052, 0.7352736928883721)\n",
      "EVAL Accuracy 5 (0.6275846795602278, 0.7251420454545454)\n",
      "TRAIN Accuracy 6 (0.6015506176387563, 0.7687295752413132)\n",
      "EVAL Accuracy 6 (0.6034886647354473, 0.7485795454545454)\n",
      "TRAIN Accuracy 7 (0.5719709049252902, 0.7872957517119015)\n",
      "EVAL Accuracy 7 (0.5795024958523837, 0.765625)\n",
      "TRAIN Accuracy 8 (0.5428555737523472, 0.7999795752413132)\n",
      "EVAL Accuracy 8 (0.5570858689871702, 0.7727272727272727)\n",
      "TRAIN Accuracy 9 (0.5154294603011187, 0.811928104653078)\n",
      "EVAL Accuracy 9 (0.5367764830589294, 0.7819602272727273)\n",
      "TRAIN Accuracy 10 (0.4900651931762695, 0.8205678105354309)\n",
      "EVAL Accuracy 10 (0.51852163401517, 0.7869318181818182)\n",
      "TRAIN Accuracy 11 (0.46666744842248803, 0.8292279411764706)\n",
      "EVAL Accuracy 11 (0.5020287890325893, 0.7954545454545454)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Model Building\n",
    "Epcohs=12\n",
    "for i in range(Epcohs):\n",
    "    result=train()\n",
    "    print(\"TRAIN Accuracy\",i,result)\n",
    "    evalResult=evaluate()\n",
    "    print(\"EVAL Accuracy\",i,evalResult)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The  model predicts wuth an accuracy of 79.54%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2470, 1683])\n"
     ]
    }
   ],
   "source": [
    "permutedXTest=x_test.permute(1,0)\n",
    "print(permutedXTest.shape)\n",
    "permutedXTest\n",
    "\n",
    "model.eval()\n",
    "prediction = torch.sigmoid(model(permutedXTest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7760)\n",
      "torch.Size([1683]) 1683 torch.Size([1683]) torch.Size([1683])\n"
     ]
    }
   ],
   "source": [
    "# print(prediction[0:100])\n",
    "# print(y_test[0:100])\n",
    "# accuracy(prediction[0:10],y_test[0:10])\n",
    "pred_round = torch.round(prediction).squeeze(1)\n",
    "correct = (pred_round == y_test).float()  \n",
    "print(correct.sum() / len(correct))\n",
    "print(y_test.shape,len(correct),pred_round.shape,correct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##From the above,the model seems to predict approximately 77.6%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
